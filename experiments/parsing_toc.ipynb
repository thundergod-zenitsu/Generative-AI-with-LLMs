{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5928491",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.6' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/rishabharya/Documents/Projects/Coursera/Generative-AI-with-LLMs/.venv/bin/python -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip uninstall docx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3fb691",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'exceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstatistics\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Counter, defaultdict\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdocx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WD_PARAGRAPH_ALIGNMENT\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfitz\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/docx.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     TAGS \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;167;01mPendingDeprecationWarning\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlogging\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'exceptions'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Auto TOC generator for messy DOCX and PDFs.\n",
    "\n",
    "pip install python-docx pymupdf docx\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import statistics\n",
    "from collections import Counter, defaultdict\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "\n",
    "import fitz  # PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------- Helpers for DOCX ----------\n",
    "def _get_run_font_size_pt(run):\n",
    "    \"\"\"Return run font size in points if available, else None.\"\"\"\n",
    "    try:\n",
    "        s = run.font.size\n",
    "        if s is None:\n",
    "            return None\n",
    "        # s is a docx.shared.Length which usually has .pt\n",
    "        try:\n",
    "            return float(s.pt)\n",
    "        except Exception:\n",
    "            # fallback if it's already numeric\n",
    "            return float(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def _get_paragraph_max_font_size_pt(para):\n",
    "    \"\"\"Return the largest run font size in a paragraph, or paragraph style font size, or None.\"\"\"\n",
    "    sizes = []\n",
    "    for run in para.runs:\n",
    "        sz = _get_run_font_size_pt(run)\n",
    "        if sz:\n",
    "            sizes.append(sz)\n",
    "    # try style font-size if no runs report size\n",
    "    try:\n",
    "        sty_sz = para.style.font.size\n",
    "        if sty_sz:\n",
    "            try:\n",
    "                sizes.append(float(sty_sz.pt))\n",
    "            except Exception:\n",
    "                sizes.append(float(sty_sz))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return max(sizes) if sizes else None\n",
    "\n",
    "\n",
    "# numbering detection regexes\n",
    "NUM_RE_1 = re.compile(r'^\\s*(?P<num>(?:\\d+\\.)+\\d*|\\d+)\\b[.\\-:)]*\\s*(?P<title>.*)', re.I)\n",
    "NUM_RE_CHAPTER = re.compile(r'^\\s*(chapter|section)\\s+(?P<num>[\\dIVXLCDMivxlcdm\\.]+)\\b[.\\-:)]*\\s*(?P<title>.*)', re.I)\n",
    "\n",
    "\n",
    "def extract_docx_headings_improved(docx_path, min_score=2, dedupe_threshold_ratio=0.6):\n",
    "    \"\"\"\n",
    "    Returns list of heading dicts: {\"text\", \"level\", \"page\": None, \"score\", \"reason\"}.\n",
    "    - min_score: pick paragraphs with score >= min_score\n",
    "    - dedupe_threshold_ratio: if a candidate text appears on > ratio * total_paragraphs, it's probably header/footer and removed\n",
    "    \"\"\"\n",
    "    doc = Document(docx_path)\n",
    "    paras = [p for p in doc.paragraphs if p.text and p.text.strip()]\n",
    "    p_infos = []\n",
    "    # gather font sizes for median computation\n",
    "    all_font_sizes = []\n",
    "    for p in paras:\n",
    "        size = _get_paragraph_max_font_size_pt(p)\n",
    "        if size:\n",
    "            all_font_sizes.append(size)\n",
    "\n",
    "    median_size = statistics.median(all_font_sizes) if all_font_sizes else None\n",
    "    total_paras = max(1, len(paras))\n",
    "\n",
    "    for i, p in enumerate(paras):\n",
    "        text = p.text.strip()\n",
    "        num_words = len(text.split())\n",
    "        style_name = getattr(p.style, \"name\", \"\") or \"\"\n",
    "        style_level = None\n",
    "        if style_name.lower().startswith(\"heading\"):\n",
    "            # try to extract numeric level (Heading 1, Heading 2, ...)\n",
    "            m = re.search(r'(\\d+)', style_name)\n",
    "            style_level = int(m.group(1)) if m else 1\n",
    "\n",
    "        max_size = _get_paragraph_max_font_size_pt(p)\n",
    "        is_bold = any((run.bold is True) for run in p.runs)\n",
    "        alignment = getattr(p, \"alignment\", None)\n",
    "        is_center = alignment == WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "        # numbering checks\n",
    "        num_level = None\n",
    "        starts_numbering = False\n",
    "        m = NUM_RE_1.match(text)\n",
    "        if m:\n",
    "            starts_numbering = True\n",
    "            num_text = m.group(\"num\")\n",
    "            # numeric level = count of dot-separated parts\n",
    "            num_level = len(num_text.split('.'))\n",
    "            # keep the rest of title if present\n",
    "            text_no_num = m.group(\"title\").strip() or text\n",
    "        else:\n",
    "            m2 = NUM_RE_CHAPTER.match(text)\n",
    "            if m2:\n",
    "                starts_numbering = True\n",
    "                num_level = 1  # treat chapter/section as top level\n",
    "                text_no_num = m2.group(\"title\").strip() or text\n",
    "            else:\n",
    "                text_no_num = text\n",
    "\n",
    "        # compute score heuristics\n",
    "        score = 0\n",
    "        reasons = []\n",
    "        if style_level:\n",
    "            score += 10\n",
    "            reasons.append(\"explicit heading style\")\n",
    "        if starts_numbering:\n",
    "            score += 4\n",
    "            reasons.append(\"starts with numbering\")\n",
    "        if max_size and median_size:\n",
    "            # if significantly larger than median, add score proportional to difference\n",
    "            if max_size >= median_size + 1.0:\n",
    "                # bigger -> more likely heading\n",
    "                delta = max_size - median_size\n",
    "                add = 2 if delta < 3 else 4\n",
    "                score += add\n",
    "                reasons.append(f\"font size bigger than median by {delta:.1f}pt\")\n",
    "        if is_bold:\n",
    "            score += 1\n",
    "            reasons.append(\"bold run\")\n",
    "        if is_center:\n",
    "            score += 1\n",
    "            reasons.append(\"centered\")\n",
    "        if num_words <= 12:\n",
    "            score += 1\n",
    "            reasons.append(\"short length\")\n",
    "\n",
    "        p_infos.append({\n",
    "            \"index\": i,\n",
    "            \"text\": text,\n",
    "            \"text_no_num\": text_no_num,\n",
    "            \"style_level\": style_level,\n",
    "            \"max_font_size_pt\": max_size,\n",
    "            \"is_bold\": is_bold,\n",
    "            \"is_center\": is_center,\n",
    "            \"starts_numbering\": starts_numbering,\n",
    "            \"num_level\": num_level,\n",
    "            \"num_words\": num_words,\n",
    "            \"score\": score,\n",
    "            \"reasons\": reasons\n",
    "        })\n",
    "\n",
    "    # pick candidates\n",
    "    candidates = [p for p in p_infos if p[\"score\"] >= min_score or p[\"style_level\"]]\n",
    "    # dedupe likely running headers/footers: if same text appears many times across document, ignore\n",
    "    text_counter = Counter([c[\"text\"].lower() for c in candidates])\n",
    "    filtered = []\n",
    "    for c in candidates:\n",
    "        cnt = text_counter[c[\"text\"].lower()]\n",
    "        if cnt > dedupe_threshold_ratio * total_paras:\n",
    "            # skip repeating header/footer\n",
    "            continue\n",
    "        filtered.append(c)\n",
    "\n",
    "    if not filtered:\n",
    "        # fallback: relax threshold to include best scored ones\n",
    "        candidates_sorted = sorted(p_infos, key=lambda x: x[\"score\"], reverse=True)\n",
    "        filtered = candidates_sorted[:max(1, int(len(candidates_sorted) * 0.05))]  # top 5% at least\n",
    "\n",
    "    # determine level mapping\n",
    "    # priority: style_level -> numbering depth -> font-size tiers\n",
    "    # build font-size tiers\n",
    "    sizes = sorted({c[\"max_font_size_pt\"] for c in filtered if c[\"max_font_size_pt\"]}, reverse=True)\n",
    "    size_to_level = {s: i + 1 for i, s in enumerate(sizes)}  # largest size => level 1\n",
    "\n",
    "    headings = []\n",
    "    for c in filtered:\n",
    "        level = None\n",
    "        if c[\"style_level\"]:\n",
    "            level = c[\"style_level\"]\n",
    "        elif c[\"num_level\"]:\n",
    "            # num level typically indicates nesting directly\n",
    "            level = c[\"num_level\"]\n",
    "        elif c[\"max_font_size_pt\"] and c[\"max_font_size_pt\"] in size_to_level:\n",
    "            level = size_to_level[c[\"max_font_size_pt\"]]\n",
    "        else:\n",
    "            # default low-level heading\n",
    "            level = 2\n",
    "        headings.append({\n",
    "            \"text\": c[\"text_no_num\"],\n",
    "            \"level\": int(level),\n",
    "            \"page\": None,\n",
    "            \"score\": c[\"score\"],\n",
    "            \"reasons\": c[\"reasons\"]\n",
    "        })\n",
    "\n",
    "    # sort by occurrence in document (index)\n",
    "    headings_sorted = sorted(headings, key=lambda h: next((p[\"index\"] for p in p_infos if p[\"text_no_num\"] == h[\"text\"]), 0))\n",
    "    return headings_sorted\n",
    "\n",
    "\n",
    "# ---------- Helpers for PDF ----------\n",
    "NUM_RE_PDF = re.compile(r'^\\s*(?P<num>(?:\\d+\\.)+\\d*|\\d+|chapter\\s+\\d+)\\b[.\\-:)]*\\s*(?P<title>.*)', re.I)\n",
    "\n",
    "\n",
    "def extract_pdf_headings_improved(pdf_path, size_delta_threshold=1.0, dedupe_threshold_ratio=0.6):\n",
    "    \"\"\"\n",
    "    Extract headings from PDF using PyMuPDF (fitz).\n",
    "    - size_delta_threshold: how many points above median size to consider a span heading candidate\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    all_spans = []\n",
    "    for page_num, page in enumerate(doc):\n",
    "        # get dict for structured access\n",
    "        page_dict = page.get_text(\"dict\")\n",
    "        for block in page_dict.get(\"blocks\", []):\n",
    "            for line in block.get(\"lines\", []):\n",
    "                for span in line.get(\"spans\", []):\n",
    "                    text = span.get(\"text\", \"\").strip()\n",
    "                    if not text:\n",
    "                        continue\n",
    "                    size = span.get(\"size\", None)\n",
    "                    if size is None:\n",
    "                        continue\n",
    "                    all_spans.append({\n",
    "                        \"text\": text,\n",
    "                        \"size\": float(size),\n",
    "                        \"page\": page_num + 1\n",
    "                    })\n",
    "\n",
    "    if not all_spans:\n",
    "        return []\n",
    "\n",
    "    sizes = [s[\"size\"] for s in all_spans]\n",
    "    median_size = statistics.median(sizes)\n",
    "\n",
    "    # candidate spans are those large enough or starting with numbering\n",
    "    candidates = []\n",
    "    for s in all_spans:\n",
    "        starts_num = bool(NUM_RE_PDF.match(s[\"text\"]))\n",
    "        if s[\"size\"] >= median_size + size_delta_threshold or starts_num:\n",
    "            candidates.append(s)\n",
    "\n",
    "    # merge consecutive spans on same page if they come from same line (simple grouping by page+text)\n",
    "    # dedupe headers that repeat across many pages\n",
    "    text_page_counts = Counter([ (c[\"text\"].lower(), c[\"page\"]) for c in candidates ])\n",
    "    # find texts that appear on many pages\n",
    "    text_counts_across_pages = Counter([ c[\"text\"].lower() for c in candidates ])\n",
    "    filtered = []\n",
    "    num_pages = len(doc)\n",
    "    for c in candidates:\n",
    "        if text_counts_across_pages[c[\"text\"].lower()] > dedupe_threshold_ratio * num_pages:\n",
    "            continue  # likely running header/footer\n",
    "        filtered.append(c)\n",
    "\n",
    "    if not filtered:\n",
    "        # fallback to best by size\n",
    "        filtered = sorted(candidates, key=lambda x: x[\"size\"], reverse=True)[:50]\n",
    "\n",
    "    # map unique sizes to levels\n",
    "    unique_sizes = sorted({c[\"size\"] for c in filtered}, reverse=True)\n",
    "    size_to_level = {s: i + 1 for i, s in enumerate(unique_sizes)}\n",
    "\n",
    "    headings = []\n",
    "    # avoid duplicates of the same (text,page) pair\n",
    "    seen = set()\n",
    "    for c in filtered:\n",
    "        key = (c[\"text\"].strip(), c[\"page\"])\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "\n",
    "        # numbering level if present\n",
    "        m = NUM_RE_PDF.match(c[\"text\"])\n",
    "        num_level = None\n",
    "        text_no_num = c[\"text\"]\n",
    "        if m:\n",
    "            num = m.group(\"num\")\n",
    "            # count numeric segments if dot separated\n",
    "            if '.' in num:\n",
    "                num_level = len(num.split('.'))\n",
    "            else:\n",
    "                num_level = 1\n",
    "            # remove number from title portion if present\n",
    "            text_no_num = (m.group(\"title\") or c[\"text\"]).strip() or c[\"text\"]\n",
    "\n",
    "        level = size_to_level.get(c[\"size\"], 2)\n",
    "        if num_level:\n",
    "            # try to use numbering depth as override (but keep it reasonable)\n",
    "            level = min(level, num_level)\n",
    "\n",
    "        headings.append({\n",
    "            \"text\": text_no_num,\n",
    "            \"level\": int(level),\n",
    "            \"page\": c[\"page\"],\n",
    "            \"size\": c[\"size\"]\n",
    "        })\n",
    "\n",
    "    # sort by page and appearance (we don't have exact order within page beyond collection order)\n",
    "    headings_sorted = sorted(headings, key=lambda h: (h[\"page\"], -h.get(\"size\", 0)))\n",
    "    return headings_sorted\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791c1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Printing / Export ----------\n",
    "def pretty_print_toc(headings, source_name=\"DOCX/PDF\"):\n",
    "    print(f\"\\nExtracted TOC ({source_name}):\")\n",
    "    for h in headings:\n",
    "        indent = \"  \" * (max(0, h[\"level\"] - 1))\n",
    "        page = f\" (p.{h['page']})\" if h.get(\"page\") else \"\"\n",
    "        print(f\"{indent}- {h['text']}{page}\")\n",
    "\n",
    "\n",
    "def export_toc_markdown(headings):\n",
    "    lines = []\n",
    "    for h in headings:\n",
    "        indent = \"  \" * (max(0, h[\"level\"] - 1))\n",
    "        lines.append(f\"{indent}- {h['text']}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3704973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Example usage ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # DOCX example\n",
    "    docx_file = \"example_messy.docx\"\n",
    "    try:\n",
    "        docx_headings = extract_docx_headings_improved(docx_file)\n",
    "        pretty_print_toc(docx_headings, source_name=\"DOCX\")\n",
    "    except Exception as e:\n",
    "        print(\"DOCX extraction failed:\", e)\n",
    "\n",
    "    # PDF example\n",
    "    pdf_file = \"example_long.pdf\"\n",
    "    try:\n",
    "        pdf_headings = extract_pdf_headings_improved(pdf_file)\n",
    "        pretty_print_toc(pdf_headings, source_name=\"PDF\")\n",
    "    except Exception as e:\n",
    "        print(\"PDF extraction failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a918ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df87cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd01e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbff1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a03ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
